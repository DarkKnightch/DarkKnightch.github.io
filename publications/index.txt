1:"$Sreact.fragment"
2:I[3719,["17","static/chunks/17-9c04c9413a9f9f1f.js","874","static/chunks/874-6cc630662f3664af.js","862","static/chunks/862-15038af301665bb3.js","177","static/chunks/app/layout-6f80bd26db56b04f.js"],"ThemeProvider"]
3:I[768,["17","static/chunks/17-9c04c9413a9f9f1f.js","874","static/chunks/874-6cc630662f3664af.js","862","static/chunks/862-15038af301665bb3.js","177","static/chunks/app/layout-6f80bd26db56b04f.js"],"default"]
4:I[7555,[],""]
5:I[1295,[],""]
6:I[2548,["17","static/chunks/17-9c04c9413a9f9f1f.js","874","static/chunks/874-6cc630662f3664af.js","862","static/chunks/862-15038af301665bb3.js","177","static/chunks/app/layout-6f80bd26db56b04f.js"],"default"]
8:I[9665,[],"MetadataBoundary"]
a:I[9665,[],"OutletBoundary"]
d:I[4911,[],"AsyncMetadataOutlet"]
f:I[9665,[],"ViewportBoundary"]
11:I[6614,[],""]
:HL["/_next/static/css/19bf7477d82f620e.css","style"]
0:{"P":null,"b":"-3Ayk5h3O4Dnmwy5nUMGe","p":"","c":["","publications",""],"i":false,"f":[[["",{"children":[["slug","publications","d"],{"children":["__PAGE__",{}]}]},"$undefined","$undefined",true],["",["$","$1","c",{"children":[[["$","link","0",{"rel":"stylesheet","href":"/_next/static/css/19bf7477d82f620e.css","precedence":"next","crossOrigin":"$undefined","nonce":"$undefined"}]],["$","html",null,{"lang":"en","className":"scroll-smooth","suppressHydrationWarning":true,"children":[["$","head",null,{"children":[["$","link",null,{"rel":"icon","href":"/favicon.svg","type":"image/svg+xml"}],["$","link",null,{"rel":"dns-prefetch","href":"https://google-fonts.jialeliu.com"}],["$","link",null,{"rel":"preconnect","href":"https://google-fonts.jialeliu.com","crossOrigin":""}],["$","link",null,{"rel":"preload","as":"style","href":"https://google-fonts.jialeliu.com/css2?family=Inter:wght@300;400;500;600;700&family=Crimson+Text:ital,wght@0,400;0,600;1,400&display=swap"}],["$","link",null,{"rel":"stylesheet","id":"gfonts-css","href":"https://google-fonts.jialeliu.com/css2?family=Inter:wght@300;400;500;600;700&family=Crimson+Text:ital,wght@0,400;0,600;1,400&display=swap","media":"print"}],["$","script",null,{"dangerouslySetInnerHTML":{"__html":"\n              (function(){\n                var l = document.getElementById('gfonts-css');\n                if (!l) return;\n                if (l.media !== 'all') {\n                  l.addEventListener('load', function(){ try { l.media = 'all'; } catch(e){} });\n                }\n              })();\n            "}}],["$","noscript",null,{"children":["$","link",null,{"rel":"stylesheet","href":"https://google-fonts.jialeliu.com/css2?family=Inter:wght@300;400;500;600;700&family=Crimson+Text:ital,wght@0,400;0,600;1,400&display=swap"}]}],["$","script",null,{"dangerouslySetInnerHTML":{"__html":"\n              try {\n                const theme = localStorage.getItem('theme-storage');\n                const parsed = theme ? JSON.parse(theme) : null;\n                const setting = parsed?.state?.theme || 'system';\n                const prefersDark = typeof window !== 'undefined' && window.matchMedia && window.matchMedia('(prefers-color-scheme: dark)').matches;\n                const effective = setting === 'dark' ? 'dark' : (setting === 'light' ? 'light' : (prefersDark ? 'dark' : 'light'));\n                var root = document.documentElement;\n                root.classList.add(effective);\n                root.setAttribute('data-theme', effective);\n              } catch (e) {\n                var root = document.documentElement;\n                root.classList.add('light');\n                root.setAttribute('data-theme', 'light');\n              }\n            "}}]]}],["$","body",null,{"className":"font-sans antialiased","children":["$","$L2",null,{"children":[["$","$L3",null,{"items":[{"title":"About","type":"page","target":"about","href":"/"},{"title":"Publications","type":"page","target":"publications","href":"/publications"}],"siteTitle":"Homepage of Siyuan Li","enableOnePageMode":false}],["$","main",null,{"className":"min-h-screen pt-16 lg:pt-20","children":["$","$L4",null,{"parallelRouterKey":"children","error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L5",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":[[["$","title",null,{"children":"404: This page could not be found."}],["$","div",null,{"style":{"fontFamily":"system-ui,\"Segoe UI\",Roboto,Helvetica,Arial,sans-serif,\"Apple Color Emoji\",\"Segoe UI Emoji\"","height":"100vh","textAlign":"center","display":"flex","flexDirection":"column","alignItems":"center","justifyContent":"center"},"children":["$","div",null,{"children":[["$","style",null,{"dangerouslySetInnerHTML":{"__html":"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}"}}],["$","h1",null,{"className":"next-error-h1","style":{"display":"inline-block","margin":"0 20px 0 0","padding":"0 23px 0 0","fontSize":24,"fontWeight":500,"verticalAlign":"top","lineHeight":"49px"},"children":404}],["$","div",null,{"style":{"display":"inline-block"},"children":["$","h2",null,{"style":{"fontSize":14,"fontWeight":400,"lineHeight":"49px","margin":0},"children":"This page could not be found."}]}]]}]}]],[]],"forbidden":"$undefined","unauthorized":"$undefined"}]}],["$","$L6",null,{"lastUpdated":"November 27, 2025"}]]}]}]]}]]}],{"children":[["slug","publications","d"],["$","$1","c",{"children":[null,["$","$L4",null,{"parallelRouterKey":"children","error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L5",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","forbidden":"$undefined","unauthorized":"$undefined"}]]}],{"children":["__PAGE__",["$","$1","c",{"children":["$L7",["$","$L8",null,{"children":"$L9"}],null,["$","$La",null,{"children":["$Lb","$Lc",["$","$Ld",null,{"promise":"$@e"}]]}]]}],{},null,false]},null,false]},null,false],["$","$1","h",{"children":[null,["$","$1","XHlBKMcowPkJt0w-asjI8",{"children":[["$","$Lf",null,{"children":"$L10"}],null]}],null]}],false]],"m":"$undefined","G":["$11","$undefined"],"s":false,"S":true}
12:"$Sreact.suspense"
13:I[4911,[],"AsyncMetadata"]
15:I[6669,["17","static/chunks/17-9c04c9413a9f9f1f.js","178","static/chunks/178-595a94b9af1e67b5.js","748","static/chunks/748-1f3129a1e6365cf9.js","182","static/chunks/app/%5Bslug%5D/page-1c9de6c76ad55e3b.js"],"default"]
9:["$","$12",null,{"fallback":null,"children":["$","$L13",null,{"promise":"$@14"}]}]
16:T507,@inproceedings{li2025basis,
  title = {Basis Function Learning for Variable-Length and Continuous-Indexed Signals},
  author = {Li, Siyuan and Cheng, Lei and Yin, Feng and Li, Jianlong and Gerstoft, Peter},
  booktitle = {ICASSP 2025-2025 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages = {1--5},
  year = {2025},
  organization = {IEEE},
  abstract = {Representing variable-length and continuous-indexed signals through a linear combination of basis functions poses a fundamental challenge in science and engineering. Current approaches resort to preprocessing steps, such as interpolation and extrapolation, to handle irregular and off-grid measurements, which compromise the physical nature of signals and degrade the representation performance. To address this challenge, rather than utilizing discrete vectors, we introduce a Bayesian functional representation model that capitalizes on the continuous nature and rich expressiveness of Gaussian processes to facilitate interpretable and effective basis function learning. Moreover, an analytical and efficient algorithm based on the variational inference framework is developed. Experimental results using real-life datasets demonstrate the superior performance of our proposed method.}
}17:T692,The probability distribution of three-dimensional sound speed fields (3D SSFs) in an ocean region encapsulates vital information about their variations, serving as valuable data-driven priors for SSF inversion tasks. However, learning such a distribution is challenging due to the high dimensionality and complexity of 3D SSFs. To tackle this challenge, we propose employing the diffusion model, a cutting-edge deep generative model that has showcased remarkable performance in diverse domains, including image and audio processing. Nonetheless, applying this approach to 3D ocean SSFs encounters two primary hurdles. First, the lack of publicly available well-crafted 3D SSF datasets impedes training and evaluation. Second, 3D SSF data consist of multiple 2D layers with varying variances, which can lead to uneven denoising during the reverse process. To surmount these obstacles, we introduce a novel 3D SSF dataset called 3DSSF, specifically designed for training and evaluating deep generative models. In addition, we devise a high-capacity neural architecture for the diffusion model to effectively handle variations in 3D sound speeds. Furthermore, we employ state-of-the-art continuous-time-based optimization method and predictor-corrector scheme for high-performance training and sampling. Notably, this paper presents the first evaluation of the diffusion model's effectiveness in generating 3D SSF data. Numerical experiments validate the proposed method's strong ability to learn the underlying data distribution of 3D SSFs, and highlight its effectiveness in assisting SSF inversion tasks and subsequently characterizing the transmission loss of underwater acoustics.18:T856,@article{li2024learning,
  title = {Learning data distribution of three-dimensional ocean sound speed fields via diffusion models},
  author = {Li, Siyuan and Cheng, Lei and Li, Jun and Wang, Zichen and Li, Jianlong},
  journal = {The Journal of the Acoustical Society of America},
  volume = {155},
  number = {5},
  pages = {3410--3425},
  year = {2024},
  publisher = {AIP Publishing},
  abstract = {The probability distribution of three-dimensional sound speed fields (3D SSFs) in an ocean region encapsulates vital information about their variations, serving as valuable data-driven priors for SSF inversion tasks. However, learning such a distribution is challenging due to the high dimensionality and complexity of 3D SSFs. To tackle this challenge, we propose employing the diffusion model, a cutting-edge deep generative model that has showcased remarkable performance in diverse domains, including image and audio processing. Nonetheless, applying this approach to 3D ocean SSFs encounters two primary hurdles. First, the lack of publicly available well-crafted 3D SSF datasets impedes training and evaluation. Second, 3D SSF data consist of multiple 2D layers with varying variances, which can lead to uneven denoising during the reverse process. To surmount these obstacles, we introduce a novel 3D SSF dataset called 3DSSF, specifically designed for training and evaluating deep generative models. In addition, we devise a high-capacity neural architecture for the diffusion model to effectively handle variations in 3D sound speeds. Furthermore, we employ state-of-the-art continuous-time-based optimization method and predictor-corrector scheme for high-performance training and sampling. Notably, this paper presents the first evaluation of the diffusion model's effectiveness in generating 3D SSF data. Numerical experiments validate the proposed method's strong ability to learn the underlying data distribution of 3D SSFs, and highlight its effectiveness in assisting SSF inversion tasks and subsequently characterizing the transmission loss of underwater acoustics.},
  doi = {https://doi.org/10.1121/10.0026026}
}19:T5fb,Reconstructing a three-dimensional ocean sound speed field (SSF) from limited and noisy measurements presents an ill-posed and challenging inverse problem. Existing methods used a number of pre-specified priors (e.g., low-rank tensor and tensor neural network structures) to address this issue. However, the SSFs are often too complex to be accurately described by these pre-defined priors. While utilizing neural network-based priors trained on historical SSF data may be a viable workaround, acquiring SSF data remains a nontrivial task. This work starts with a key observation: Although natural images and SSFs admit fairly different characteristics, their denoising processes appear to share similar traits—as both remove random components from more structured signals. This observation allows us to incorporate deep denoisers trained using extensive natural images to realize zero-shot SSF reconstruction, without any extra training or network modifications. To implement this idea, an alternating direction method of multipliers (ADMM) algorithm using such a deep denoiser is proposed, which is reminiscent of the plug-and-play scheme from medical imaging. Our plug-and-play framework is tailored for SSF recovery such that the learned denoiser can be simultaneously used with other handcrafted SSF priors. Extensive numerical studies show that the new framework largely outperforms state-of-the-art baselines, especially under widely recognized challenging scenarios, e.g., when the SSF samples are taken as tensor fibers.1a:T7a8,@article{li2024zero,
  title = {Zero-shot reconstruction of ocean sound speed field tensors: A deep plug-and-play approach},
  author = {Li, Siyuan and Cheng, Lei and Fu, Xiao and Li, Jianlong},
  journal = {The Journal of the Acoustical Society of America},
  volume = {155},
  number = {5},
  pages = {3475--3489},
  year = {2024},
  publisher = {AIP Publishing},
  abstract = {Reconstructing a three-dimensional ocean sound speed field (SSF) from limited and noisy measurements presents an ill-posed and challenging inverse problem. Existing methods used a number of pre-specified priors (e.g., low-rank tensor and tensor neural network structures) to address this issue. However, the SSFs are often too complex to be accurately described by these pre-defined priors. While utilizing neural network-based priors trained on historical SSF data may be a viable workaround, acquiring SSF data remains a nontrivial task. This work starts with a key observation: Although natural images and SSFs admit fairly different characteristics, their denoising processes appear to share similar traits—as both remove random components from more structured signals. This observation allows us to incorporate deep denoisers trained using extensive natural images to realize zero-shot SSF reconstruction, without any extra training or network modifications. To implement this idea, an alternating direction method of multipliers (ADMM) algorithm using such a deep denoiser is proposed, which is reminiscent of the plug-and-play scheme from medical imaging. Our plug-and-play framework is tailored for SSF recovery such that the learned denoiser can be simultaneously used with other handcrafted SSF priors. Extensive numerical studies show that the new framework largely outperforms state-of-the-art baselines, especially under widely recognized challenging scenarios, e.g., when the SSF samples are taken as tensor fibers.},
  doi = {https://doi.org/10.1121/10.0026125}
}1b:T49b,Accurately reconstructing a three-dimensional (3D) ocean sound speed field (SSF) is essential for various ocean acoustic applications, but the sparsity and uncertainty of sound speed samples across a vast ocean region make it a challenging task. To tackle this challenge, a large body of reconstruction methods has been developed, including spline interpolation, matrix or tensor-based completion, and deep neural networks (DNNs)-based reconstruction. However, a principled analysis of their effectiveness in 3D SSF reconstruction is still lacking. This paper performs a thorough analysis of the reconstruction error and highlights the need for a balanced representation model that integrates expressiveness and conciseness. To meet this requirement, a 3D SSF-tailored tensor DNN is proposed, which uses tensor computations and DNN architectures to achieve remarkable 3D SSF reconstruction. The proposed model not only includes the previous tensor-based SSF representation model as a special case but also has a natural ability to reject noise. The numerical results using the South China Sea 3D SSF data demonstrate that the proposed method outperforms state-of-the-art methods.1c:T679,@article{li2023striking,
  title = {Striking the right balance: Three-dimensional ocean sound speed field reconstruction using tensor neural networks},
  author = {Li, Siyuan and Cheng, Lei and Zhang, Ting and Zhao, Hangfang and Li, Jianlong},
  journal = {The Journal of the Acoustical Society of America},
  volume = {154},
  number = {2},
  pages = {1106--1123},
  year = {2023},
  publisher = {AIP Publishing},
  abstract = {Accurately reconstructing a three-dimensional (3D) ocean sound speed field (SSF) is essential for various ocean acoustic applications, but the sparsity and uncertainty of sound speed samples across a vast ocean region make it a challenging task. To tackle this challenge, a large body of reconstruction methods has been developed, including spline interpolation, matrix or tensor-based completion, and deep neural networks (DNNs)-based reconstruction. However, a principled analysis of their effectiveness in 3D SSF reconstruction is still lacking. This paper performs a thorough analysis of the reconstruction error and highlights the need for a balanced representation model that integrates expressiveness and conciseness. To meet this requirement, a 3D SSF-tailored tensor DNN is proposed, which uses tensor computations and DNN architectures to achieve remarkable 3D SSF reconstruction. The proposed model not only includes the previous tensor-based SSF representation model as a special case but also has a natural ability to reject noise. The numerical results using the South China Sea 3D SSF data demonstrate that the proposed method outperforms state-of-the-art methods.},
  doi = {https://doi.org/10.1121/10.0020670}
}1d:T60e,Reconstructing ocean sound speed field (SSF) from limited and noisy measurements/estimates is crucial for many ocean acoustic applications, including underwater tomography, target localization/tracking, and communications. Classical reconstruction methods include deterministic approaches (e.g., spline interpolation) and geostatistical methods (e.g., kriging). They exhibit a strong link to linear regression and Gaussian process regression in machine learning (ML) literature, by uniformly viewing them as supervised regression models that learn the mapping from the geographical locations to the sound speed outputs. From a unified ML perspective, theoretical analysis indicates that classical reconstruction methods have several drawbacks, such as the sensitivity to noises and high computational cost. To overcome these drawbacks, inspired by the recent thriving development of graph machine learning, we introduce graph-guided Bayesian low-rank matrix completions (LRMCs) for fine-scale and accurate ocean SSF reconstruction. In particular, a more general graph-guided LRMC model is proposed that encompasses the state-of-the-art one as a special case. The proposed model and the associated inference algorithm simultaneously exploit the global (low-rankness) and local (graph structure) information of ocean sound speed data, thus striking an outstanding balance of reconstruction accuracy and computational complexity. Numerical results using real-life ocean SSF data have demonstrated the encouraging performances of the proposed approaches.1e:T7c8,@article{li2023graph,
  title = {Graph-guided Bayesian matrix completion for ocean sound speed field reconstruction},
  author = {Li, Siyuan and Cheng, Lei and Zhang, Ting and Zhao, Hangfang and Li, Jianlong},
  journal = {The Journal of the Acoustical Society of America},
  volume = {153},
  number = {1},
  pages = {689--710},
  year = {2023},
  publisher = {AIP Publishing},
  abstract = {Reconstructing ocean sound speed field (SSF) from limited and noisy measurements/estimates is crucial for many ocean acoustic applications, including underwater tomography, target localization/tracking, and communications. Classical reconstruction methods include deterministic approaches (e.g., spline interpolation) and geostatistical methods (e.g., kriging). They exhibit a strong link to linear regression and Gaussian process regression in machine learning (ML) literature, by uniformly viewing them as supervised regression models that learn the mapping from the geographical locations to the sound speed outputs. From a unified ML perspective, theoretical analysis indicates that classical reconstruction methods have several drawbacks, such as the sensitivity to noises and high computational cost. To overcome these drawbacks, inspired by the recent thriving development of graph machine learning, we introduce graph-guided Bayesian low-rank matrix completions (LRMCs) for fine-scale and accurate ocean SSF reconstruction. In particular, a more general graph-guided LRMC model is proposed that encompasses the state-of-the-art one as a special case. The proposed model and the associated inference algorithm simultaneously exploit the global (low-rankness) and local (graph structure) information of ocean sound speed data, thus striking an outstanding balance of reconstruction accuracy and computational complexity. Numerical results using real-life ocean SSF data have demonstrated the encouraging performances of the proposed approaches.},
  doi = {https://doi.org/10.1121/10.0017064}
}7:["$","div",null,{"className":"max-w-4xl mx-auto px-4 sm:px-6 lg:px-8 py-12","children":[["$","$L15",null,{"config":{"type":"publication","title":"Publications","description":"A collection of my research work.","source":"publications.bib"},"publications":[{"id":"li2025basis","title":"Basis Function Learning for Variable-Length and Continuous-Indexed Signals","authors":[{"name":"Siyuan Li","isHighlighted":false,"isCorresponding":false,"isCoAuthor":false},{"name":"Lei Cheng","isHighlighted":false,"isCorresponding":false,"isCoAuthor":false},{"name":"Feng Yin","isHighlighted":false,"isCorresponding":false,"isCoAuthor":false},{"name":"Jianlong Li","isHighlighted":false,"isCorresponding":false,"isCoAuthor":false},{"name":"Peter Gerstoft","isHighlighted":false,"isCorresponding":false,"isCoAuthor":false}],"year":2025,"type":"conference","status":"published","tags":[],"keywords":"$7:props:children:0:props:publications:0:tags","researchArea":"signal-processing","journal":"","conference":"ICASSP 2025-2025 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","pages":"1--5","abstract":"Representing variable-length and continuous-indexed signals through a linear combination of basis functions poses a fundamental challenge in science and engineering. Current approaches resort to preprocessing steps, such as interpolation and extrapolation, to handle irregular and off-grid measurements, which compromise the physical nature of signals and degrade the representation performance. To address this challenge, rather than utilizing discrete vectors, we introduce a Bayesian functional representation model that capitalizes on the continuous nature and rich expressiveness of Gaussian processes to facilitate interpretable and effective basis function learning. Moreover, an analytical and efficient algorithm based on the variational inference framework is developed. Experimental results using real-life datasets demonstrate the superior performance of our proposed method.","description":"This paper introducs a Bayesian functional representation model to facilitate interpretable and effective basis function learning.","selected":true,"preview":"CBFL.png","bibtex":"$16"},{"id":"li2024learning","title":"Learning data distribution of three-dimensional ocean sound speed fields via diffusion models","authors":[{"name":"Siyuan Li","isHighlighted":false,"isCorresponding":false,"isCoAuthor":false},{"name":"Lei Cheng","isHighlighted":false,"isCorresponding":false,"isCoAuthor":false},{"name":"Jun Li","isHighlighted":false,"isCorresponding":false,"isCoAuthor":false},{"name":"Zichen Wang","isHighlighted":false,"isCorresponding":false,"isCoAuthor":false},{"name":"Jianlong Li","isHighlighted":false,"isCorresponding":false,"isCoAuthor":false}],"year":2024,"type":"journal","status":"published","tags":[],"keywords":"$7:props:children:0:props:publications:1:tags","researchArea":"machine-learning","journal":"The Journal of the Acoustical Society of America","conference":"","volume":"155","issue":"5","pages":"3410--3425","doi":"https://doi.org/10.1121/10.0026026","code":"https://github.com/OceanSTARLab/DiffusionSSF","abstract":"$17","description":"This paper presents the first evaluation of the diffusion model's effectiveness in generating 3D SSF data.","selected":true,"preview":"DiffusionSSF.png","bibtex":"$18"},{"id":"li2024zero","title":"Zero-shot reconstruction of ocean sound speed field tensors: A deep plug-and-play approach","authors":[{"name":"Siyuan Li","isHighlighted":false,"isCorresponding":false,"isCoAuthor":false},{"name":"Lei Cheng","isHighlighted":false,"isCorresponding":false,"isCoAuthor":false},{"name":"Xiao Fu","isHighlighted":false,"isCorresponding":false,"isCoAuthor":false},{"name":"Jianlong Li","isHighlighted":false,"isCorresponding":false,"isCoAuthor":false}],"year":2024,"type":"journal","status":"published","tags":[],"keywords":"$7:props:children:0:props:publications:2:tags","researchArea":"machine-learning","journal":"The Journal of the Acoustical Society of America","conference":"","volume":"155","issue":"5","pages":"3475--3489","doi":"https://doi.org/10.1121/10.0026125","code":"https://github.com/OceanSTARLab/DeepPnP","abstract":"$19","description":"This paper proposes a tailored plug-and-play framework with image denoiser for SSF recovery.","selected":false,"preview":"Deeppnp.png","bibtex":"$1a"},{"id":"li2023striking","title":"Striking the right balance: Three-dimensional ocean sound speed field reconstruction using tensor neural networks","authors":[{"name":"Siyuan Li","isHighlighted":false,"isCorresponding":false,"isCoAuthor":false},{"name":"Lei Cheng","isHighlighted":false,"isCorresponding":false,"isCoAuthor":false},{"name":"Ting Zhang","isHighlighted":false,"isCorresponding":false,"isCoAuthor":false},{"name":"Hangfang Zhao","isHighlighted":false,"isCorresponding":false,"isCoAuthor":false},{"name":"Jianlong Li","isHighlighted":false,"isCorresponding":false,"isCoAuthor":false}],"year":2023,"type":"journal","status":"published","tags":["Tensor decomposotion","Neural network","Inverse problem"],"keywords":"$7:props:children:0:props:publications:3:tags","researchArea":"neural-networks","journal":"The Journal of the Acoustical Society of America","conference":"","volume":"154","issue":"2","pages":"1106--1123","doi":"https://doi.org/10.1121/10.0020670","code":"https://github.com/OceanSTARLab/Tensor-Neural-Network","abstract":"$1b","description":"This paper proposes a 3D SSF-tailored tensor DNN is proposed, which uses tensor computations and DNN architectures to achieve remarkable 3D SSF reconstruction.","selected":true,"preview":"TNN.png","bibtex":"$1c"},{"id":"li2023graph","title":"Graph-guided Bayesian matrix completion for ocean sound speed field reconstruction","authors":[{"name":"Siyuan Li","isHighlighted":false,"isCorresponding":false,"isCoAuthor":false},{"name":"Lei Cheng","isHighlighted":false,"isCorresponding":false,"isCoAuthor":false},{"name":"Ting Zhang","isHighlighted":false,"isCorresponding":false,"isCoAuthor":false},{"name":"Hangfang Zhao","isHighlighted":false,"isCorresponding":false,"isCoAuthor":false},{"name":"Jianlong Li","isHighlighted":false,"isCorresponding":false,"isCoAuthor":false}],"year":2023,"type":"journal","status":"published","tags":[],"keywords":"$7:props:children:0:props:publications:4:tags","researchArea":"machine-learning","journal":"The Journal of the Acoustical Society of America","conference":"","volume":"153","issue":"1","pages":"689--710","doi":"https://doi.org/10.1121/10.0017064","code":"https://github.com/OceanSTARLab/Graph-guided-Bayesian-Matrix-Completion","abstract":"$1d","description":"This paper introduces graph-guided Bayesian low-rank matrix completions (LRMCs) for fine-scale and accurate ocean SSF reconstruction.","selected":false,"preview":"BMCG.png","bibtex":"$1e"}]}],false,false]}]
c:null
10:[["$","meta","0",{"charSet":"utf-8"}],["$","meta","1",{"name":"viewport","content":"width=device-width, initial-scale=1"}]]
b:null
14:{"metadata":[["$","title","0",{"children":"Publications | Homepage of Siyuan Li"}],["$","meta","1",{"name":"description","content":"A collection of my research work."}],["$","meta","2",{"name":"author","content":"Siyuan Li"}],["$","meta","3",{"name":"keywords","content":"Siyuan Li,PhD,Research,Zhejiang University"}],["$","meta","4",{"name":"creator","content":"Siyuan Li"}],["$","meta","5",{"name":"publisher","content":"Siyuan Li"}],["$","meta","6",{"property":"og:title","content":"Homepage of Siyuan Li"}],["$","meta","7",{"property":"og:description","content":"PhD student at the Zhejiang University."}],["$","meta","8",{"property":"og:site_name","content":"Siyuan Li's Academic Website"}],["$","meta","9",{"property":"og:locale","content":"en_US"}],["$","meta","10",{"property":"og:type","content":"website"}],["$","meta","11",{"name":"twitter:card","content":"summary"}],["$","meta","12",{"name":"twitter:title","content":"Homepage of Siyuan Li"}],["$","meta","13",{"name":"twitter:description","content":"PhD student at the Zhejiang University."}],["$","link","14",{"rel":"icon","href":"/favicon.svg"}]],"error":null,"digest":"$undefined"}
e:{"metadata":"$14:metadata","error":null,"digest":"$undefined"}
